<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <!-- Please delete this script if you use this HTML. -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-7580334-1');
  </script>
  <meta name="viewport" content="width=500">
  <link href="stylesheet.css" rel="stylesheet" type="text/css">
  <link rel="icon" type="image/png" href="images/goethe.jpg">
  <title>Kshitij Dwivedi</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Kshitij Dwivedi</name>
              </p>
              <p>I am a PhD student at <a href="http://www.cvai.cs.uni-frankfurt.de/index.html">cvai lab</a> in Goethe University Frankfurt, where I am advised by Prof. Gemma Roig.
              </p>
              <p>
                Before starting my PhD I've worked as an Engineer at  <a href="https://bicr.atr.jp/dni/">Kamitani lab</a>  in <a href="https://www.atr.jp/index_e.html">ATR</a>, Japan and Samsung R&D India. I did my Bachelors and Masters in Electrical Engineering at <a href="https://www.iitk.ac.in/">IIT Kanpur</a>.
              </p>
              <p align=center>
                <a href="mailto:kshitijdwivedi93@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Kshitij_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.in/citations?user=i9ZQlCYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/public-profile/in/kshitij-dwivedi-5613131b/"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/kd_circle.png">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Interests</heading>
              <p>
                I am interested in understanding how human visual cortex work and then apply the gained insights towards creating agents with lifelong learning capabilities. I collaborate with <a href="https://www.ewi-psy.fu-berlin.de/en/einrichtungen/arbeitsbereiche/neural_dyn_of_vis_cog/team_v2/index.html">Radek Cichy's lab </a>and <a href="https://bonnerlab.org/"> Michael Bonner's lab</a> towards achieving my research goal. Below you can find my publications related to Computer and Human Vision.
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Computer Vision</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="porlight_stop()" onmouseover="porlight_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='porlight_image'><img src='images/DDS_2.png'></div>
                <img src='images/DDS_1.png'>
              </div>
              <script type="text/javascript">
                function porlight_start() {
                  document.getElementById('porlight_image').style.opacity = "1";
                }

                function porlight_stop() {
                  document.getElementById('porlight_image').style.opacity = "0";
                }
                porlight_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2008.02107">
                <papertitle>Duality Diagram Similarity: a generic framework for initialization selection in task transfer learning</papertitle>
              </a>
              <br>
              <strong>Kshitij Dwivedi</strong>,  Jiahui Huang,
              <a href="http://userpage.fu-berlin.de/rmcichy/">Radoslaw Martin Cichy</a>,
              <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">Gemma Roig</a>
              <br>
              <em>ECCV</em>, 2020
              <br>
              <br>
              <p></p>
              <p>Highly efficient and accurate approach for initialization selection in task transfer learning.</p>
            </td>
          </tr>

          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/RSA_2.png'></div>
                <img src='images/RSA_small.png'>
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }

                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/1904.11740">
                <papertitle>Representation Similarity Analysis for Efficient Task taxonomy & Transfer Learning</papertitle>
              </a>
              <br>
              <strong>Kshitij Dwivedi</strong>,
              <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">Gemma Roig</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <p></p>
              <p>Efficient method to estimate task similarities and its application to transfer learning</p>
            </td>
          </tr>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Human Vision</heading>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

            <tr onmouseout="mpi_stop()" onmouseover="mpi_start()">
              <td width="25%">
                <div class="one">
                  <div class="two" id='mpi_image'><img src='images/jocn1.png'></div>
                  <img src='images/jocn2.png'>
                </div>
                <script type="text/javascript">
                  function mpi_start() {
                    document.getElementById('mpi_image').style.opacity = "1";
                  }

                  function mpi_stop() {
                    document.getElementById('mpi_image').style.opacity = "0";
                  }
                  mpi_stop()
                </script>
              </td>
              <td valign="middle" width="75%">
                <a href="https://www.biorxiv.org/content/10.1101/2020.03.10.985309v1">
                  <papertitle>Unravelling Representations in Scene-selective Brain Regions Using Scene Parsing Deep Neural Networks</papertitle>
                </a>
                <br>
                <strong>Kshitij Dwivedi</strong>,
                <a href="http://userpage.fu-berlin.de/rmcichy/">Radoslaw Martin Cichy</a>,
                <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">Gemma Roig</a>,
                <br>
                <em>accepted in Journal of Cognitive Neuroscience</em>, 2020 &nbsp
                <br>
                <a href="https://www.biorxiv.org/content/10.1101/2020.03.10.985309v1">bioRxiv</a> /
                <a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Dwivedi_Navigational_affordance_cortical_responses_explained_by_scene-parsing_model_ECCVW_2018_paper.pdf">ECCV workshop 2018</a>
                <p></p>
                <p>We show that a scene parsing model explains human scene-selective responses better than a scene classification model. Further, components predicted by scene parsing models can be used to distinguish functional roles of human scene-selective areas PPA and OPA.</p>
              </td>
            </tr>
          <tr onmouseout="unprocessing_stop()" onmouseover="unprocessing_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='unprocessing_image'><img src='images/FN1.png'></div>
                <img src='images/FN1.png'>
              </div>
              <script type="text/javascript">
                function unprocessing_start() {
                  document.getElementById('unprocessing_image').style.opacity = "1";
                }

                function unprocessing_stop() {
                  document.getElementById('unprocessing_image').style.opacity = "0";
                }
                unprocessing_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://www.frontiersin.org/articles/10.3389/fncom.2019.00021/full">
                <papertitle>End-to-End Deep Image Reconstruction From Human Brain Activity</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=7CibvPgAAAAJ&hl=en">Guohua Shen*</a>,
              <strong>Kshitij Dwivedi*</strong>,
              <a href="https://researchmap.jp/majima/?lang=english"> Kei Majima </a>,
              <a href="https://bicr.atr.jp/~horikawa-t/">Tomoyasu Horikawa</a>,
              <a href="https://bicr.atr.jp/dni/en/members/kamitani_e/">Yukiyasu Kamitani</a>
              <br>
              <em>Frontiers in Computational Neuroscience</em>, 2019

              <br>
              <em>* denotes equal contribution</em>
              <p></p>
              <p>Reconstructing perceived images from human fMRI responses.</p>
            </td>
          </tr>

          <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='motionblur_image'><img src='images/ccn2.png'></div>
                <img src='images/ccn1.png'>
              </div>
              <script type="text/javascript">
                function motionblur_start() {
                  document.getElementById('motionblur_image').style.opacity = "1";
                }

                function motionblur_stop() {
                  document.getElementById('motionblur_image').style.opacity = "0";
                }
                motionblur_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://ccneuro.org/2019/proceedings/0000102.pdf">
                <papertitle>Explaining Scene-selective Visual Areas Using Task-specific Deep Neural Network Representations</papertitle>
              </a>
              <br>

              <strong>Kshitij Dwivedi</strong>,
              <a href="https://bonnerlab.org/people">Michael F. Bonner</a>,
              <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">Gemma Roig</a>,
              <br>
              <em>Conference on Cognitive Computational Neuroscience (CCN) </em>, 2019
              <br>
              <p></p>
              <p>In this work, we demonstrate the potential of finding functions of visual cortex from functions of deep neural networks. Specifically, we distinguished the functional roles of scene selective regions OPA and PPA using deep neural networks.</p>
            </td>
          </tr>

          <tr onmouseout="darkflash_stop()" onmouseover="darkflash_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='darkflash_image'><img src='images/algo.png'></div>
                <img src='images/algo.png'>
              </div>
              <script type="text/javascript">
                function darkflash_start() {
                  document.getElementById('darkflash_image').style.opacity = "1";
                }

                function darkflash_stop() {
                  document.getElementById('darkflash_image').style.opacity = "0";
                }
                darkflash_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/1905.05675">
                <papertitle>The Algonauts Project: A Platform for Communication between the Sciences of Biological and Artificial Intelligence
          </papertitle>
              </a>
              <br>
              <a href="http://userpage.fu-berlin.de/rmcichy/">Radoslaw Martin Cichy</a>,
              <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">Gemma Roig</a>,
              <a href="https://www.alexandonian.com/">Alex Andonian</a>,
              <strong>Kshitij Dwivedi</strong>,
              <a href="http://people.csail.mit.edu/blahner/">Benjamin Lahner</a>,
              <a href="https://www.alexlascelles.com/">Alex Lascelles</a>,
              <a href="https://mohsenzadehlab.com/people">Yalda Mohsenzadeh</a>,
              <a href="https://people.csail.mit.edu/krama/">Kandan Ramakrishnan</a>,
              <a href="http://olivalab.mit.edu/audeoliva.html"> Aude Oliva</a>
              <br>
              <em>Conference on Cognitive Computational Neuroscience (CCN) </em>, 2019
              <br>
              <a href="http://algonauts.csail.mit.edu/"> Workshop</a>
              <p></p>
              <p>
                We organized a challenge and workshop to predict human fMRI and MEG responses using computational models.
              </p>
            </td>
          </tr>



          <tr onmouseout="loss_stop()" onmouseover="loss_start()" >
            <td width="25%">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/b1.png'></div>
                <img src='images/biorxiv1.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://www.biorxiv.org/content/10.1101/402735v1.abstract">
                <papertitle>Task-specific vision models explain task-specific areas of visual cortex</papertitle>
              </a>
              <br>
              <strong>Kshitij Dwivedi</strong>,
              <a href="http://www.cvai.cs.uni-frankfurt.de/team.html">Gemma Roig</a>
              <br>
              <em>bioRxiv</em>, 2018
              <br>
              <p></p>
              <p>We show that we can gain insights into functions of brain regions by comparing the human fMRI responses in a given region to activations of deep neural networks trained on diverse set of tasks.</p>
            </td>
          </tr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Conference abstracts and Workshop Papers</heading>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
              <td valign="Left" width="100%">
                <a href="https://www.crowdcast.io/e/neuromatch2/40">
                  <papertitle>Unveiling functions of visual cortex using task-specific deep neural networks</papertitle>
                </a>
                <br>
                <strong>Kshitij Dwivedi</strong>, Michael F. Bonner, Radoslaw Martin Cichy, Gemma Roig
                <br>
                <em>Neuromatch 2.0 </em>, 2020 &nbsp <font color="red"><strong>(Short talk)</strong></font>
                <br>
                <p></p>
              </td>
            </tr>
            <tr onmouseout="motionstereo_stop()" onmouseover="motionstereo_start()">
              <td valign="left" width="100%">
                <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/CEFRL/Huang_Deep_Anchored_Convolutional_Neural_Networks_CVPRW_2019_paper.pdf">
                  <papertitle>Deep Anchored Convolutional Neural Networks</papertitle>
                </a>
                <br>
                Jiahui Huang,<strong>Kshitij Dwivedi</strong>, Gemma Roig
                <br>
                <em>Computer Vision and Pattern Recognition Workshop (CVPRW) on Compact and Efficient Feature Representation and Learning (CEFRL)</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/CEFRL/Huang_Deep_Anchored_Convolutional_Neural_Networks_CVPRW_2019_paper.pdf">pdf</a>
                <p></p>
                <p> Neural network compression using convolutional parameters sharing.</p>
              </td>
            </tr>
            <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
              <td valign="left" width="100%">
                <a href="https://jov.arvojournals.org/article.aspx?articleid=2750681">
                  <papertitle>Explaining Scene-selective Visual Area Using Task-specific and Category Specific DNN Units</papertitle>
                </a>
                <br>
                <strong>Kshitij Dwivedi</strong>, Michael F. Bonner, Gemma Roig
                <br>
                <em>Vision Sciences Society Conference</em>, 2019
                <br>
                <a href="https://jov.arvojournals.org/article.aspx?articleid=2750681">Abstract</a>

                <p></p>
              </td>
            </tr>
            <tr onmouseout="motionstereo_stop()" onmouseover="motionstereo_start()">

              <td valign="left" width="100%">
                <a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Dwivedi_Navigational_affordance_cortical_responses_explained_by_scene-parsing_model_ECCVW_2018_paper.pdf">
                  <papertitle>Navigational Affordance Cortical Responses Explained by Semantic Segmentation model</papertitle>
                </a>
                <br>
                <strong>Kshitij Dwivedi</strong>, Gemma Roig
                <br>
                <em>European Conference on Computer Vision Workshops (ECCVW) on Brain-Driven Computer Vision (BDCV)</em>, 2018
                <br>
                <a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Dwivedi_Navigational_affordance_cortical_responses_explained_by_scene-parsing_model_ECCVW_2018_paper.pdf">pdf</a>
                <p></p>
                <p> Relating functions of visual cortex to deep neural network functions.</p>
              </td>
            </tr>

            <tr onmouseout="motionstereo_stop()" onmouseover="motionstereo_start()">
              <td valign="left" width="100%">
                <a href="https://drive.google.com/file/d/0BwO69G0kg_oCWTJtUDhpbE9YU0haOUtQSWJVSnl3OTRjMkg0/view">
                  <papertitle>Plug and Play DNN Modules for Multi-domain Learning</papertitle>
                </a>
                <br>
                <strong>Kshitij Dwivedi</strong>, Gemma Roig
                <br>
                <em>European Conference on Computer Vision Workshops (ECCVW) on Interactive and Adaptive Learning in an Open World (IAL)</em>, 2018
                <br>
                <a href="https://drive.google.com/file/d/0BwO69G0kg_oCWTJtUDhpbE9YU0haOUtQSWJVSnl3OTRjMkg0/view">pdf</a>
                <p></p>
                <p> Efficient multi-domain learning using parameter sharing.</p>
              </td>
            </tr>
            <tr onmouseout="motionstereo_stop()" onmouseover="motionstereo_start()">
              <td valign="middle" width="100%">
                <a href="https://r2learning.github.io/assets/papers/CameraReadySubmission%2019.pdf">
                  <papertitle>Importance of object selection in Relational Reasoning tasks</papertitle>
                </a>
                <br>
                <strong>Kshitij Dwivedi</strong>, Gemma Roig
                <br>
                <em>Neural Information Processing Systems Workshops on Relation Representation Learning (R2L)</em>, 2018
                <br>
                <a href="https://r2learning.github.io/assets/papers/CameraReadySubmission%2019.pdf">pdf</a>
                <p></p>
                <p></p>
              </td>
            </tr>





        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="5%"><img src="images/nma.png"></td>
            <td width="95%" valign="center">
              <a href="https://www.neuromatchacademy.org/">Lead TA, Neuromatch Academy 2020</a>
            </td>
          </tr>
          <tr>
            <td width="5%"><img src="images/iitk.png"></td>
            <td width="95%" valign="center">
              <a href="https://www.iitk.ac.in/">TA, Data Structure and Algorithms 2014, IIT Kanpur </a>
            </td>
          </tr>

      </td>
    </tr>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                I stole the template from this great <a href="https://jonbarron.info/">homepage</a>,
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
